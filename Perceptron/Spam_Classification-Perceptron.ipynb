{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We want this validation set because we want to see if the classifier works before we apply it for the test set\n",
      "total errors: \n",
      "33351\n",
      "training error rate: \n",
      "0.0\n",
      "validation error rate: \n",
      "0.02\n",
      "------------------------\n",
      "15 words with the most negative weights: \n",
      "prefer\n",
      "wrote\n",
      "but\n",
      "and\n",
      "reserv\n",
      "i\n",
      "still\n",
      "technolog\n",
      "on\n",
      "url\n",
      "sinc\n",
      "instead\n",
      "upgrad\n",
      "recipi\n",
      "copyright\n",
      "-------------------------\n",
      "15 words with the most positive weights: \n",
      "emerg\n",
      "june\n",
      "junk\n",
      "book\n",
      "boot\n",
      "leader\n",
      "settl\n",
      "leav\n",
      "lead\n",
      "troubl\n",
      "entir\n",
      "english\n",
      "percent\n",
      "know\n",
      "basenumb\n",
      "5: \n",
      "0.027\n",
      "0.016\n",
      "8: \n",
      "0.025\n",
      "0.018\n",
      "3: \n",
      "0.047\n",
      "0.017\n",
      "11: \n",
      "0.02\n",
      "0.018\n",
      "-----------------------\n",
      "Report on Validation Error Rate:\n",
      "5 iterations, normal:0.336663336663, average:0.336663336663\n",
      "8 iterations, normal:0.328671328671, average:0.31968031968\n",
      "3 iterations, normal:0.360639360639, average:0.318681318681\n",
      "11 iterations, normal:0.311688311688, average:0.317682317682\n",
      "Best configuration: 11 iterations using normal training function\n",
      "-----------------------\n",
      "validation error rate for test.txt: \n",
      "0.021\n"
     ]
    }
   ],
   "source": [
    "#Discussed with Erika Lage, Ivy Chen, Meet Barot and Emma Zhu \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Part1-Splitting data into two sets\n",
    "train=open(\"/Users/guzi/Documents/nyu/nyu-senior/2nd-semester/machine learning/problemset/ps1_data/spam_train.txt\");\n",
    "data=train.read().split(\"\\n\");\n",
    "training=data[:4000];\n",
    "validate=data[4000:];\n",
    "print 'We want this validation set because we want to see if the classifier works before we apply it for the test set'\n",
    "\n",
    "\n",
    "#Part2-Building a vocablist; transform all data into feature vectors\n",
    "dictionary={};\n",
    "for x in training:\n",
    "    words=x.split();\n",
    "    vocab=set(words[1:]);\n",
    "    for i in vocab:\n",
    "        if i in dictionary:\n",
    "            dictionary[i]+=1;\n",
    "        else:\n",
    "            dictionary[i]=1;\n",
    "            \n",
    "vocablist=[];\n",
    "for x in dictionary:\n",
    "    if dictionary[x]>=30:\n",
    "        vocablist.append(x);\n",
    " \n",
    "\n",
    "\n",
    "#transform emails into vectors, each email consists of 1s and 0s with class as the first element\n",
    "z=0;\n",
    "for email in training:\n",
    "    list=email.split();        \n",
    "    vector=[];\n",
    "    vector.append(list[0])\n",
    "    \n",
    "    temp={};\n",
    "    for i in set(list[1:]):\n",
    "       temp[i]=1\n",
    "    \n",
    "    for x in vocablist:\n",
    "        if x in temp: #ignore the first element which is class\n",
    "            vector.append(1)\n",
    "        else:\n",
    "            vector.append(0)  \n",
    "    training[z]=vector;\n",
    "    z+=1;\n",
    "\n",
    "#Part3-Implement perceptron_train(data) and perceptron_test(w,data)\n",
    "def perceptron_train(data,maxpass):\n",
    "    iter=0;\n",
    "    w=np.zeros(len(vocablist));\n",
    "    error=0;\n",
    "    k=100\n",
    "    while k!=0 and iter<maxpass:  \n",
    "        k=0\n",
    "        for feature_vector in data:\n",
    "            y=int(feature_vector[0]);\n",
    "            x=np.array(feature_vector[1:])\n",
    "            dot=np.dot(w,x)         \n",
    "            if dot>=0:\n",
    "                predict=1\n",
    "            else:\n",
    "                predict=0\n",
    "            if y!=predict:\n",
    "                if y==0:\n",
    "                    y=-1\n",
    "                k+=1;\n",
    "                error+=k;\n",
    "                w=w+y*x;\n",
    "        iter+=1;\n",
    "    array=[w,error,iter];\n",
    "    return array;\n",
    "            \n",
    "def perceptron_test(w,data):\n",
    "    percent=0\n",
    "    error=0\n",
    "    for email in data:\n",
    "        y=int(email[0])\n",
    "        x=np.array(email[1:])\n",
    "        dot=np.dot(w,x)\n",
    "        if dot>=0:\n",
    "            predict=1\n",
    "        else:\n",
    "            predict=0\n",
    "        if predict!=y:\n",
    "            error+=1           \n",
    "    percent=error/(len(data)*1.0)\n",
    "    return percent\n",
    "    \n",
    "#Part4-Train the linear classifier using my training set.\n",
    "result=perceptron_train(training,1000);\n",
    "mistakes=result[1];\n",
    "print 'total errors: '\n",
    "print (mistakes)\n",
    "\n",
    "errors=perceptron_test(result[0],training)\n",
    "print 'training error rate: '\n",
    "print (errors)\n",
    "\n",
    "\n",
    "#testing validation set, turning 1000 validation information into feature vector\n",
    "s=0;\n",
    "for aaa in validate:\n",
    "    if aaa==\"\":\n",
    "        print 'aaa is an empty string'\n",
    "    list_validate=aaa.split();\n",
    "    vector_validate=[];\n",
    "    bug=list_validate[0];\n",
    "    vector_validate.append(bug);\n",
    "\n",
    "    validate_temp={};\n",
    "    for i in set(list_validate[1:]):\n",
    "       validate_temp[i]=1\n",
    "    \n",
    "    for x in vocablist:\n",
    "        if x in validate_temp: #ignore the first element which is class\n",
    "            vector_validate.append(1)\n",
    "        else:\n",
    "            vector_validate.append(0)  \n",
    "    validate[s]=vector_validate;\n",
    "    s+=1;\n",
    "validation=perceptron_test(result[0],validate)\n",
    "print 'validation error rate: '\n",
    "print (validation)\n",
    "\n",
    "\n",
    "#Part5-output the 15 words with most positive weights\n",
    "array=result[0];\n",
    "print '------------------------'\n",
    "print '15 words with the most negative weights: '\n",
    "weight=np.argsort(array)\n",
    "for i in range(15):\n",
    "    print vocablist[weight[i]]\n",
    "print'-------------------------'\n",
    "print '15 words with the most positive weights: '\n",
    "array_r=np.sort(array);\n",
    "reverse=np.argsort(array_r[::-1])\n",
    "for i in range(15):\n",
    "    print vocablist[reverse[i]]\n",
    "\n",
    "#Part6-Average perceptron\n",
    "def average_perceptron(data,maxpass):\n",
    "    iter=0;\n",
    "    w=np.zeros(len(vocablist));\n",
    "    total=w;\n",
    "    w_num=0;\n",
    "    error=0;\n",
    "    k=100\n",
    "    while k!=0 and iter<maxpass:  \n",
    "        k=0\n",
    "        for feature_vector in data:\n",
    "            y=int(feature_vector[0]);\n",
    "            x=np.array(feature_vector[1:])\n",
    "            dot=np.dot(w,x)         \n",
    "            if dot>=0:\n",
    "                predict=1\n",
    "            else:\n",
    "                predict=0\n",
    "            if y!=predict:\n",
    "                if y==0:\n",
    "                    y=-1\n",
    "                k+=1;\n",
    "                error+=k;\n",
    "                w=w+y*x;\n",
    "            total+=w;\n",
    "            w_num+=1;\n",
    "        iter+=1;\n",
    "    w=total/w_num;\n",
    "    array=[w,error,iter];\n",
    "    return array;\n",
    "\n",
    "#Part7-Varying the amount of training data\n",
    "#Part8-Perceptron iteration, plotting graphs\n",
    "\n",
    "numbers=[100,200,400,800,2000,4000];\n",
    "errors=[]\n",
    "error_averages=[]\n",
    "iterations=[]\n",
    "allemails=training+validate;\n",
    "for n in numbers:\n",
    "    outcome=perceptron_train(allemails[:n],1000)\n",
    "    iteration=outcome[2];\n",
    "    iterations.append(iteration);\n",
    "    error=perceptron_test(outcome[0],allemails[n:])\n",
    "    errors.append(error);\n",
    "    outcome_average=average_perceptron(allemails[:n],1000)\n",
    "    error_average=perceptron_test(outcome_average[0],allemails[n:])\n",
    "    error_averages.append(error_average)\n",
    "    \n",
    "plt.plot(numbers,errors)\n",
    "plt.show()\n",
    "plt.plot(numbers,error_averages)\n",
    "plt.show()\n",
    "plt.plot(numbers,iterations)    \n",
    "plt.show()\n",
    "\n",
    "\n",
    "#9-add arguments\n",
    "#10-play around with iteration argument\n",
    "\n",
    "print '-----------------------'\n",
    "print 'Report on Validation Error Rate:' \n",
    "print \"5 iterations, normal:0.027, average:0.016\"\n",
    "print \"8 iterations, normal:0.025, average:0.018\"\n",
    "print \"3 iterations, normal:0.047, average:0.017\"\n",
    "print \"11 iterations, normal:0.02, average:0.018\"\n",
    "print \"Best configuration: 5 iterations using average training function\"\n",
    "\n",
    "\n",
    "\n",
    "print '-----------------------'\n",
    "test=open(\"/Users/guzi/Documents/nyu/nyu-senior/2nd-semester/machine learning/problemset/ps1_data/spam_test.txt\");\n",
    "tester=test.read().split(\"\\n\");\n",
    "j=0;\n",
    "for bbb in tester:\n",
    "    list_tester=bbb.split();        \n",
    "    vector_tester=[];\n",
    "    vector_tester.append(list_tester[0])\n",
    "    \n",
    "    tester_temp={};\n",
    "    for i in set(list_tester[1:]):\n",
    "       tester_temp[i]=1\n",
    "    \n",
    "    for x in vocablist:\n",
    "        if x in tester_temp: #ignore the first element which is class\n",
    "            vector_tester.append(1)\n",
    "        else:\n",
    "            vector_tester.append(0)  \n",
    "    tester[j]=vector_tester;\n",
    "    j+=1;\n",
    "tester=perceptron_test(result[0],tester)\n",
    "print 'validation error rate for test.txt: '\n",
    "print (tester)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
